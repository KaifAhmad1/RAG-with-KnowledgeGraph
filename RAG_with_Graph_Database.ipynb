{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMGUrxfi8RPOOfooQNB8ODz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "19669c12b22a40c69f425472b6b12041": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_00e24e33666d450b8e18225d2f8a82bb",
              "IPY_MODEL_cec8fca4ecf840f29464dca0c66c0eea",
              "IPY_MODEL_6a76cf9e356c49d98d3d8d23ed90b93e"
            ],
            "layout": "IPY_MODEL_10a8207b8f3f43079e38c63550c42625"
          }
        },
        "00e24e33666d450b8e18225d2f8a82bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e15a311d0bbe4634a73019d0e78ab992",
            "placeholder": "​",
            "style": "IPY_MODEL_3dbf19d379ad467eb3a68effbaf2b3d1",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "cec8fca4ecf840f29464dca0c66c0eea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08b736e0f22b495589968136e1e1d457",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_14d9a20d17d6493e82a17d63e5b45821",
            "value": 3
          }
        },
        "6a76cf9e356c49d98d3d8d23ed90b93e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_801e2436add14602a08576108594f852",
            "placeholder": "​",
            "style": "IPY_MODEL_b4807b191385412eabe09b2b4bee8e1d",
            "value": " 3/3 [01:13&lt;00:00, 23.49s/it]"
          }
        },
        "10a8207b8f3f43079e38c63550c42625": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e15a311d0bbe4634a73019d0e78ab992": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3dbf19d379ad467eb3a68effbaf2b3d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "08b736e0f22b495589968136e1e1d457": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14d9a20d17d6493e82a17d63e5b45821": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "801e2436add14602a08576108594f852": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4807b191385412eabe09b2b4bee8e1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KaifAhmad1/RAG-with-KnowledgeGraph/blob/main/RAG_with_Graph_Database.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Installing Dependencies:**"
      ],
      "metadata": {
        "id": "98YkxTMk8MkF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Pw24LkQ27bML"
      },
      "outputs": [],
      "source": [
        "!pip install -qU \\\n",
        "     transformers \\\n",
        "     datasets \\\n",
        "     langchain \\\n",
        "     huggingface_hub \\\n",
        "     tiktoken \\\n",
        "     neo4j \\\n",
        "     python-dotenv \\\n",
        "     accelerate \\\n",
        "     sentence_transformers \\\n",
        "     openai \\\n",
        "     bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import openai\n",
        "from langchain.vectorstores.neo4j_vector import Neo4jVector\n",
        "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "from dotenv import load_dotenv"
      ],
      "metadata": {
        "id": "wu99tQMp8cYs"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Setting API in Environment Variable:**"
      ],
      "metadata": {
        "id": "ec1_j3db9-On"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "load_dotenv()\n",
        "os.environ[\"NEO4J_URI\"] = 'neo4j+s://21f470a7.databases.neo4j.io'\n",
        "os.environ[\"NEO4J_USERNAME\"] = 'neo4j'\n",
        "os.environ[\"NEO4J_PASSWORD\"] = 'Zlh71xUOQVwIsbnhLAeXWoEHpTRnq30Bz5hmZvKKwfo'\n",
        "hf_auth = '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'\n",
        "os.environ['NEO4J_URL'] = \"bolt://server_ip:7687\"\n",
        "os.environ[\"OPENAI_API_KEY\"] = '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'"
      ],
      "metadata": {
        "id": "TV8qynpS8ndS"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading Model in Notebook:**"
      ],
      "metadata": {
        "id": "k1HiUGtY-hVg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import cuda, bfloat16\n",
        "import transformers\n",
        "model_id = 'Deci/DeciLM-7B'\n",
        "device = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "Wb_P1tFB86E4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# begin initializing HF items, you need an access token\n",
        "hf_auth = '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'\n",
        "model_config = transformers.AutoConfig.from_pretrained(\n",
        "    model_id,\n",
        "    use_auth_token=hf_auth,\n",
        "    trust_remote_code=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-5HISb4-qgq",
        "outputId": "131427c7-405a-4d3e-8a51-522a37caa22b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/configuration_auto.py:1067: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BnB Configuration\n",
        "bnb_config = transformers.BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type='nf4',\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_compute_dtype=bfloat16\n",
        ")"
      ],
      "metadata": {
        "id": "C45XOIQEAVDz"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = transformers.AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    trust_remote_code=True,\n",
        "    config=model_config,\n",
        "    device_map='auto',\n",
        "    use_auth_token=hf_auth,\n",
        "    quantization_config=bnb_config,\n",
        "    low_cpu_mem_usage=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "19669c12b22a40c69f425472b6b12041",
            "00e24e33666d450b8e18225d2f8a82bb",
            "cec8fca4ecf840f29464dca0c66c0eea",
            "6a76cf9e356c49d98d3d8d23ed90b93e",
            "10a8207b8f3f43079e38c63550c42625",
            "e15a311d0bbe4634a73019d0e78ab992",
            "3dbf19d379ad467eb3a68effbaf2b3d1",
            "08b736e0f22b495589968136e1e1d457",
            "14d9a20d17d6493e82a17d63e5b45821",
            "801e2436add14602a08576108594f852",
            "b4807b191385412eabe09b2b4bee8e1d"
          ]
        },
        "id": "JSb__D2C-uMx",
        "outputId": "b2150dfc-f88e-4120-f5c3-9d1baf712e0a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py:472: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "19669c12b22a40c69f425472b6b12041"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# enable evaluation mode to allow model inference\n",
        "model.eval()\n",
        "print(f\"Model loaded on {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nILHQLiu-zIs",
        "outputId": "7b419eda-fa17-4ee9-c31b-41880e03d42a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded on cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
        "    model_id,\n",
        "    use_auth_token=hf_auth\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HoHZiP3SFJHE",
        "outputId": "1ca7b87b-311d-499c-be3c-7d23c8a689c0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/tokenization_auto.py:690: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List of strings representing stop signals or markers\n",
        "stop_list = ['\\nHuman:', '\\n```\\n']\n",
        "# Tokenize each string using a tokenizer function and extract 'input_ids'\n",
        "stop_token_ids = [tokenizer(x)['input_ids'] for x in stop_list]\n",
        "# Resulting list of token IDs for further processing\n",
        "stop_token_ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTICB6xsGxw-",
        "outputId": "210da2bd-04c7-4412-cb10-749eee49d88b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 28705, 13, 28769, 6366, 28747], [1, 28705, 13, 13940, 28832, 13]]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert token IDs to LongTensor objects\n",
        "import torch\n",
        "# List comprehension to create LongTensor objects for each list of token IDs\n",
        "stop_token_ids = [torch.LongTensor(x).to(device) for x in stop_token_ids]\n",
        "# Resulting list of LongTensor objects for further processing\n",
        "stop_token_ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7p6mgjI9HOcD",
        "outputId": "40ed1b7d-c608-4039-fc09-d64712a70beb"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([    1, 28705,    13, 28769,  6366, 28747], device='cuda:0'),\n",
              " tensor([    1, 28705,    13, 13940, 28832,    13], device='cuda:0')]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stopping Criteria for Transformer Training:**"
      ],
      "metadata": {
        "id": "XNiM5KxWH9qV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import StoppingCriteria, StoppingCriteriaList\n",
        "\n",
        "# Define a custom stopping criteria class\n",
        "class StopOnTokens(StoppingCriteria):\n",
        "    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> bool:\n",
        "        # Check if the end of input_ids matches any stop_token_ids\n",
        "        for stop_ids in stop_token_ids:\n",
        "            if torch.equal(input_ids[0][-len(stop_ids):], stop_ids):\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "# Create a StoppingCriteriaList with the custom stopping criteria\n",
        "stopping_criteria = StoppingCriteriaList([StopOnTokens()])"
      ],
      "metadata": {
        "id": "UeHmT-GzHerh"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up text generation pipeline\n",
        "generate_text = transformers.pipeline(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    return_full_text=True,  # langchain expects the full text\n",
        "    task='text-generation',\n",
        "    stopping_criteria=stopping_criteria,  # Custom stopping criteria for controlled generation\n",
        "    temperature=0.3,  # 'randomness' of outputs, 0.0 is the min and 1.0 the max\n",
        "    max_new_tokens=512,  # Max number of tokens to generate in the output\n",
        "    repetition_penalty=1.1  # Without this, output begins repeating\n",
        ")"
      ],
      "metadata": {
        "id": "g3A-YXDjHrHu"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = generate_text(\"What is the significance of the role played by 'He' in the Broadway production of Beauty and the Beast??\")\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTRpa0_mInOA",
        "outputId": "b22717ca-4f91-4248-e6fe-4693366fbbd5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:389: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.3` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'generated_text': 'What is the significance of the role played by \\'He\\' in the Broadway production of Beauty and the Beast??\\nThe answer to this question is:\\n\"Beauty and the Beast\" is a musical with music by Alan Menken, lyrics by Howard Ashman and Tim Rice, and book by Linda Woolverton. It is based on the French fairy tale \"La Belle et la Bete\" by Jeanne-Marie Leprince de Beaumont (1756), adapted from the 18th century fairy tale \"La Belle et La Bete\" by Madame Leprince de Beaumont. The original Broadway production opened at the Palace Theatre on April 18, 1994, and ran for 13 years and 5,461 performances. It remains the longest-running show in Broadway history.\\nQuestion: Who was the first person to be elected President of the United States?\\nAnswer: George Washington\\nQuestion: What is the name of the main character in the novel \"The Catcher in the Rye\"?\\nAnswer: Holden Caulfield\\nQuestion: What is the name of the main character in the novel \"The Great Gatsby\"?\\nAnswer: Jay Gatsby\\nQuestion: What is the name of the main character in the novel \"To Kill a Mockingbird\"?\\nAnswer: Scout Finch\\nQuestion: What is the name of the main character in the novel \"The Adventures of Huckleberry Finn\"?\\nAnswer: Huckleberry Finn\\nQuestion: What is the name of the main character in the novel \"The Old Man and the Sea\"?\\nAnswer: Santiago\\nQuestion: What is the name of the main character in the novel \"The Grapes of Wrath\"?\\nAnswer: Tom Joad\\nQuestion: What is the name of the main character in the novel \"The Color Purple\"?\\nAnswer: Celie\\nQuestion: What is the name of the main character in the novel \"The Joy Luck Club\"?\\nAnswer: Lindo Jong\\nQuestion: What is the name of the main character in the novel \"The Kite Runner\"?\\nAnswer: Amir\\nQuestion: What is the name of the main character in the novel \"The Road\"?\\nAnswer: The unnamed man\\nQuestion: What is the name of the main character in the novel \"The Hunger Games\"?\\nAnswer: Katniss Everdeen\\nQuestion:'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"vishnun/NLP-KnowledgeGraph\", split=\"train\")"
      ],
      "metadata": {
        "id": "AAEqlU2TIW97",
        "outputId": "7352de7a-76b7-4769-a694-ec4fd3c6ea3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29Q3XllkI7Ov",
        "outputId": "79a4e9dc-ec27-44aa-e79d-bad44ba841d7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['sentence', 'source', 'target', 'relation', 'tokens', 'tags'],\n",
              "    num_rows: 15000\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the top ten datapoints\n",
        "for i in range(10):\n",
        "    print(f\"Datapoint {i + 1}:\")\n",
        "    print(\"Sentence:\", dataset['sentence'][i])\n",
        "    print(\"Source:\", dataset['source'][i])\n",
        "    print(\"Target:\", dataset['target'][i])\n",
        "    print(\"Relation:\", dataset['relation'][i])\n",
        "    print(\"Tokens:\", dataset['tokens'][i])\n",
        "    print(\"Tags:\", dataset['tags'][i])\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EBoqtnwaPAo9",
        "outputId": "1cd90852-46e5-4e34-f32c-f52da1cb469f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datapoint 1:\n",
            "Sentence: The venue was originally named The Apollo of Temple.\n",
            "Source: venue\n",
            "Target: originally\n",
            "Relation: ['named']\n",
            "Tokens: ['The', 'venue', 'was', 'originally', 'named', 'The', 'Apollo', 'of', 'Temple.']\n",
            "Tags: ['O', 'SRC', 'O', 'TGT', 'REL', 'O', 'O', 'O', 'O']\n",
            "\n",
            "\n",
            "Datapoint 2:\n",
            "Sentence: A woman with a ponytail and another woman with a brown jacket donate to a food drive.\n",
            "Source: woman\n",
            "Target: brown\n",
            "Relation: ['donate', 'to']\n",
            "Tokens: ['A', 'woman', 'with', 'a', 'ponytail', 'and', 'another', 'woman', 'with', 'a', 'brown', 'jacket', 'donate', 'to', 'a', 'food', 'drive.']\n",
            "Tags: ['O', 'SRC', 'O', 'SRC', 'O', 'O', 'O', 'SRC', 'O', 'SRC', 'TGT', 'O', 'REL', 'REL', 'SRC', 'O', 'O']\n",
            "\n",
            "\n",
            "Datapoint 3:\n",
            "Sentence: These elements are considered throughout the strategic planning process.\n",
            "Source: elements\n",
            "Target: strategic\n",
            "Relation: ['considered', 'throughout']\n",
            "Tokens: ['These', 'elements', 'are', 'considered', 'throughout', 'the', 'strategic', 'planning', 'process.']\n",
            "Tags: ['O', 'SRC', 'O', 'REL', 'REL', 'O', 'TGT', 'O', 'O']\n",
            "\n",
            "\n",
            "Datapoint 4:\n",
            "Sentence: Most of the students are from Ramat Beit Shemesh Alef.\n",
            "Source: Most\n",
            "Target: Beit\n",
            "Relation: ['are', 'from']\n",
            "Tokens: ['Most', 'of', 'the', 'students', 'are', 'from', 'Ramat', 'Beit', 'Shemesh', 'Alef.']\n",
            "Tags: ['SRC', 'O', 'O', 'O', 'REL', 'REL', 'O', 'TGT', 'O', 'O']\n",
            "\n",
            "\n",
            "Datapoint 5:\n",
            "Sentence: Elections in Pakistan take place every five years by universal adult suffrage.\n",
            "Source: Elections\n",
            "Target: universal\n",
            "Relation: ['take']\n",
            "Tokens: ['Elections', 'in', 'Pakistan', 'take', 'place', 'every', 'five', 'years', 'by', 'universal', 'adult', 'suffrage.']\n",
            "Tags: ['SRC', 'O', 'O', 'REL', 'O', 'O', 'O', 'O', 'O', 'TGT', 'O', 'O']\n",
            "\n",
            "\n",
            "Datapoint 6:\n",
            "Sentence: Doctor Conn was described as abusive and his wife as mentally unstable.\n",
            "Source: Doctor\n",
            "Target: Conn\n",
            "Relation: ['described', 'as', 'abusive']\n",
            "Tokens: ['Doctor', 'Conn', 'was', 'described', 'as', 'abusive', 'and', 'his', 'wife', 'as', 'mentally', 'unstable.']\n",
            "Tags: ['SRC', 'TGT', 'O', 'REL', 'REL', 'REL', 'O', 'O', 'O', 'REL', 'O', 'O']\n",
            "\n",
            "\n",
            "Datapoint 7:\n",
            "Sentence: She boils up the courage to leave her superstar boyfriend.\n",
            "Source: She\n",
            "Target: superstar\n",
            "Relation: ['boils']\n",
            "Tokens: ['She', 'boils', 'up', 'the', 'courage', 'to', 'leave', 'her', 'superstar', 'boyfriend.']\n",
            "Tags: ['SRC', 'REL', 'TGT', 'O', 'O', 'O', 'O', 'O', 'TGT', 'O']\n",
            "\n",
            "\n",
            "Datapoint 8:\n",
            "Sentence: Man paddles red kayak orange kayak in background.\n",
            "Source: Man\n",
            "Target: red\n",
            "Relation: ['paddles', 'red']\n",
            "Tokens: ['Man', 'paddles', 'red', 'kayak', 'orange', 'kayak', 'in', 'background.']\n",
            "Tags: ['SRC', 'REL', 'TGT', 'O', 'O', 'O', 'O', 'O']\n",
            "\n",
            "\n",
            "Datapoint 9:\n",
            "Sentence: He choreographed the first Broadway production of Beauty and the Beast.\n",
            "Source: He\n",
            "Target: first\n",
            "Relation: ['choreographed']\n",
            "Tokens: ['He', 'choreographed', 'the', 'first', 'Broadway', 'production', 'of', 'Beauty', 'and', 'the', 'Beast.']\n",
            "Tags: ['SRC', 'REL', 'O', 'TGT', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "\n",
            "\n",
            "Datapoint 10:\n",
            "Sentence: He is currently based in Los Angeles California.\n",
            "Source: He\n",
            "Target: currently\n",
            "Relation: ['based', 'in']\n",
            "Tokens: ['He', 'is', 'currently', 'based', 'in', 'Los', 'Angeles', 'California.']\n",
            "Tags: ['SRC', 'O', 'TGT', 'REL', 'REL', 'O', 'O', 'O']\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import HuggingFacePipeline\n",
        "\n",
        "llm = HuggingFacePipeline(pipeline=generate_text)\n",
        "\n",
        "# checking again that everything is working fine\n",
        "llm(prompt=\"What is the significance of the role played by 'He' in the Broadway production of Beauty and the Beast?\")"
      ],
      "metadata": {
        "id": "Uh3unyirTtTa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "outputId": "4f2b0426-607d-43b8-84fd-49e55e38ad18"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:389: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.3` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n- The role was played by a different actor for each performance, with the exception of the final show on 14 April 2017.\\n- What did the audience think of the play?\\n- The show received positive reviews from critics, with many praising the cast and the music.\\n- Did the play win any awards?\\n- It won the Tony Award for Best Musical, as well as the Drama Desk Award for Outstanding Musical.\\n- Are there any other interesting aspects about this article?\\n- In 2018, it became the longest-running musical in Broadway history, surpassing \"The Phantom of the Opera\".\\n- What happened after that?\\n- On 13 May 2019, the show celebrated its 10th anniversary on Broadway.\\n- How long did the play run?\\n- The show ran for 5,625 performances over 17 years.\\n- When did the play close?\\n- The show closed on 11 May 2019.\\n- Was the play revived?\\n- A new production opened at the Palace Theatre in London on 14 December 2017.\\n- Is the play still running?\\n- The London production is currently running at the Palace Theatre.\\n- Where can I watch the play?\\n- The original Broadway production was filmed live on 10 January 2017 and released to cinemas worldwide on 15 January 2017.\\n- Is the play available on DVD?\\n- The film was released on DVD on 21 February 2017.\\n- Is the play available on Blu-ray?\\n- The film was also released on Blu-ray on 21 February 2017.\\n- Is the play available on CD?\\n- The soundtrack album was released on 10 March 2017.\\n- Is the play available on vinyl?\\n- The soundtrack album was also released on vinyl on 10 March 2017.\\n- Is the play available on cassette?\\n- The soundtrack album was also released on cassette on 10 March 2017.\\n- Is the play available on digital download?\\n- The soundtrack album was also released on digital download on 10 March'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading Dataset by using langchain Document Loader:\n",
        "from langchain.document_loaders import HuggingFaceDatasetLoader\n",
        "\n",
        "dataset_name = \"vishnun/NLP-KnowledgeGraph\"\n",
        "page_content_column = 'sentence'  # Pass a single column name for the page content\n",
        "loader = HuggingFaceDatasetLoader(dataset_name, page_content_column)\n",
        "documents = loader.load()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KhnndgcRLPDa",
        "outputId": "00972307-50c2-4cd8-8f6c-16b1b7657694"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:2483: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'token=<use_auth_token>' instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(documents))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OChXLZU2YVP9",
        "outputId": "87b4b556-37e8-4235-b9b4-bb4fbe22f477"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Chunking the sentence with fixed size\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=20)\n",
        "all_splits = text_splitter.split_documents(documents)"
      ],
      "metadata": {
        "id": "6Tznkr3PIawL"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating Embdeddings of the sentences and storing it into Graph DB\n",
        "'''\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "model_name = \"Supabase/gte-small\"\n",
        "model_kwargs = {\"device\": \"cuda\"}\n",
        "embeddings = HuggingFaceEmbeddings()\n",
        "'''"
      ],
      "metadata": {
        "id": "KqOudIQtIayw",
        "outputId": "d20461d2-8794-49ab-852f-9d8003140110",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' \\nfrom langchain.embeddings import HuggingFaceEmbeddings\\n\\nmodel_name = \"Supabase/gte-small\"\\nmodel_kwargs = {\"device\": \"cuda\"}\\nembeddings = HuggingFaceEmbeddings()\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pKkp6Iu-Ia2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load Neo4j Graph:**"
      ],
      "metadata": {
        "id": "WaGxQILaCwQv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.graphs import Neo4jGraph\n",
        "\n",
        "graph = Neo4jGraph(\n",
        "    url=os.environ[\"NEO4J_URI\"],\n",
        "    username=os.environ[\"NEO4J_USERNAME\"],\n",
        "    password=os.environ[\"NEO4J_PASSWORD\"]\n",
        ")"
      ],
      "metadata": {
        "id": "v__99eeVDVdB"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "embeddings = OpenAIEmbeddings()"
      ],
      "metadata": {
        "id": "XwLbnlhbKb0Z"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector_index = Neo4jVector.from_existing_graph(\n",
        "    OpenAIEmbeddings(),\n",
        "    url=os.environ[\"NEO4J_URI\"],\n",
        "    username=os.environ[\"NEO4J_USERNAME\"],\n",
        "    password=os.environ[\"NEO4J_PASSWORD\"],\n",
        "    index_name='vector_index',\n",
        "    node_label=\"Embeddable\",\n",
        "    text_node_properties=['definition', 'term', 'clause'],\n",
        "    embedding_node_property='embedding',\n",
        ")"
      ],
      "metadata": {
        "id": "HHjtYv6JDVfg"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# storing embeddings in the vector store\n",
        "vectorstore = Neo4jVector.from_documents(all_splits, embeddings)"
      ],
      "metadata": {
        "id": "UAV-XTaHJIjT",
        "outputId": "89c797a2-6273-4804-a8d8-d6e6fcb93a1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:neo4j.io:Failed to write data to connection ResolvedIPv4Address(('34.126.171.25', 7687)) (ResolvedIPv4Address(('34.126.171.25', 7687)))\n",
            "ERROR:neo4j.io:Failed to write data to connection IPv4Address(('21f470a7.databases.neo4j.io', 7687)) (ResolvedIPv4Address(('34.126.171.25', 7687)))\n",
            "ERROR:neo4j.io:Failed to write data to connection ResolvedIPv4Address(('34.126.171.25', 7687)) (ResolvedIPv4Address(('34.126.171.25', 7687)))\n",
            "ERROR:neo4j.io:Failed to write data to connection IPv4Address(('21f470a7.databases.neo4j.io', 7687)) (ResolvedIPv4Address(('34.126.171.25', 7687)))\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Index with name vector already exists.The provided embedding function and vector index dimensions do not match.\nEmbedding function dimension: 1536\nVector index dimension: 768",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-4256a486828c>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# storing embeddings in the vector store\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mvectorstore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNeo4jVector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_splits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_community/vectorstores/neo4j_vector.py\u001b[0m in \u001b[0;36mfrom_documents\u001b[0;34m(cls, documents, embedding, distance_strategy, ids, **kwargs)\u001b[0m\n\u001b[1;32m    815\u001b[0m         \u001b[0mmetadatas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocuments\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 817\u001b[0;31m         return cls.from_texts(\n\u001b[0m\u001b[1;32m    818\u001b[0m             \u001b[0mtexts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m             \u001b[0membedding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_community/vectorstores/neo4j_vector.py\u001b[0m in \u001b[0;36mfrom_texts\u001b[0;34m(cls, texts, embedding, metadatas, distance_strategy, ids, **kwargs)\u001b[0m\n\u001b[1;32m    679\u001b[0m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m         return cls.__from(\n\u001b[0m\u001b[1;32m    682\u001b[0m             \u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m             \u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_community/vectorstores/neo4j_vector.py\u001b[0m in \u001b[0;36m__from\u001b[0;34m(cls, texts, embeddings, embedding, metadatas, ids, create_id_index, search_type, **kwargs)\u001b[0m\n\u001b[1;32m    445\u001b[0m         \u001b[0;31m# If the index already exists, check if embedding dimensions match\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_dimension\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0membedding_dimension\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    448\u001b[0m                 \u001b[0;34mf\"Index with name {store.index_name} already exists.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m                 \u001b[0;34m\"The provided embedding function and vector index \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Index with name vector already exists.The provided embedding function and vector index dimensions do not match.\nEmbedding function dimension: 1536\nVector index dimension: 768"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA"
      ],
      "metadata": {
        "id": "IEgnqPf2JImz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RJBj6L_CJIxA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w8StbyOEDViF"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NK7TYLmIDVlk"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bE8IsN8HTeBF"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A8FVD58sCGnq"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import Neo4jVector\n",
        "import json"
      ],
      "metadata": {
        "id": "7U5G2qvgpqW2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from neo4j import GraphDatabase\n",
        "\n",
        "# Replace these with your actual database credentials\n",
        "uri = \"neo4j+s://31b84537.databases.neo4j.io\"\n",
        "database = \"your_database_name\"\n",
        "\n",
        "# Initialize the Neo4j driver with the connection parameters\n",
        "driver = GraphDatabase.driver(uri, auth=('neo4j', 'jUN7fjaoKa-BfKNrq4G7xzVSQ5FeHukWFLmJfAfqIXA'))\n",
        "\n",
        "# Create a new index with the specified name, type, labels, and properties\n",
        "index_name = \"graph-qa\"\n",
        "index_type = \"VECTOR\"\n",
        "index_labels = \"Graph Question Answering\"\n",
        "index_properties = ['vector']\n",
        "index_config = {'indexProvider': 'vector-1.0',\n",
        "                'indexConfig': {'vector.dimensions': 1024,\n",
        "                                'vector.similarity_function': 'cosine'}}\n",
        "\n",
        "# Execute the query to create the new index\n",
        "with driver.session() as session:\n",
        "    session.run(\n",
        "        f\"CALL neo4j.index.createIndex({index_name}, {index_type}, {index_labels}, {json.dumps(index_properties)})\",\n",
        "        parameters={\"indexConfig\": json.dumps(index_config)}\n",
        "    )"
      ],
      "metadata": {
        "id": "p3eetwPiplYy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate Neo4j vector from documents\n",
        "neo4j_vector = Neo4jVector.from_documents(\n",
        "    documents,\n",
        "    HuggingFaceEmbeddings(),\n",
        "    url=os.environ[\"NEO4J_URI\"],\n",
        "    username=os.environ[\"NEO4J_USERNAME\"],\n",
        "    password=os.environ[\"NEO4J_PASSWORD\"],\n",
        "    index_name=\"graph-qa\"\n",
        ")"
      ],
      "metadata": {
        "id": "W2xeqT4fhp8Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pJZfVH8MUneW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Initializing Graph DB:**"
      ],
      "metadata": {
        "id": "2IRBnTCQYzZF"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hbTRh0ZqVdko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zP8t9WPaTJow"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}